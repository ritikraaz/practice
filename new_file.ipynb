{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# new file"
      ],
      "metadata": {
        "id": "UIv6y6k9J4Fg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Welcome to My Notebook!\n",
        "\n",
        "#This notebook is a place to explore and analyze data using Python and various libraries. In this notebook, we'll cover:\n",
        "\n",
        "#- Loading and preprocessing data\n",
        "#- Data visualization with matplotlib and seaborn\n",
        "#- Applying machine learning algorithms using scikit-learn\n",
        "#- Drawing insights and making conclusions\n",
        "\n",
        "#Let's get started!\n"
      ],
      "metadata": {
        "id": "7MybViOSJ5el"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Data Science Programming Languages\n",
        "\n",
        "#Data science involves working with data to extract insights and make informed decisions. Here are some commonly used programming languages in the field of data science:\n",
        "\n",
        "# 1. **Python**: Widely recognized as a versatile language with rich libraries and frameworks like NumPy, pandas, scikit-learn, and TensorFlow for data manipulation, analysis, and machine learning.\n",
        "\n",
        "# 2. **R**: Known for its statistical computing capabilities, R provides a wide range of packages like ggplot2, dplyr, and caret for data visualization, manipulation, and analysis.\n",
        "\n",
        "# 3. **SQL**: Structured Query Language is essential for working with databases, querying and transforming data for analysis.\n",
        "\n",
        "# 4. **Julia**: An emerging language with a focus on high-performance numerical and scientific computing, well-suited for data analysis and modeling.\n",
        "\n",
        "# 5. **SAS**: A software suite used for advanced analytics, business intelligence, and data management.\n",
        "\n",
        "#6. **Java**: Often used in big data processing and distributed computing frameworks like Apache Hadoop and Spark.\n",
        "\n",
        "# These languages play a vital role in data science tasks, from data exploration and cleaning to advanced machine learning algorithms and statistical analysis.\n"
      ],
      "metadata": {
        "id": "5U6G1_qBKS-E"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Essential Data Science Libraries\n",
        "\n",
        "### Python Libraries:\n",
        "\n",
        "# 1. **NumPy**\n",
        "# 2. **pandas**\n",
        "# 3. **matplotlib**\n",
        "# 4. **seaborn**\n",
        "# 5. **scikit-learn**\n",
        "# 6. **TensorFlow** and **PyTorch**\n",
        "\n",
        "### R Libraries:\n",
        "\n",
        "# 1. **ggplot2**\n",
        "# 2. **dplyr** and **tidyr**\n",
        "# 3. **caret**\n",
        "# 4. **tidyverse**\n",
        "# 5. **glmnet**\n",
        "# 6. **lubridate**\n"
      ],
      "metadata": {
        "id": "OVJpRj_nKqBC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Science Tools\n",
        "#Programming Languages\n",
        "#Python\n",
        "#R\n",
        "#Julia\n",
        "#SQL\n",
        "\n",
        "#Libraries\n",
        "#NumPy\n",
        "#pandas\n",
        "#scikit-learn\n",
        "#TensorFlow\n",
        "#ggplot2\n",
        "#caret\n",
        "\n",
        "#Visualization\n",
        "#matplotlib\n",
        "#Tableau\n",
        "#Power BI\n",
        "\n",
        "#Big Data Processing\n",
        "#Apache Hadoop\n",
        "#Apache Spark\n",
        "\n",
        "#Cloud Platforms\n",
        "#AWS\n",
        "#Google Cloud Platform\n",
        "#Microsoft Azure"
      ],
      "metadata": {
        "id": "mErWrkQvLght"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Addition\n",
        "\n",
        "##Addition is the process of combining two or more numbers to get a sum.\n",
        "\n",
        "##Example: 3+5=8\n",
        "\n",
        "\n",
        "## Subtraction\n",
        "\n",
        "##Subtraction involves taking away one number from another to find the difference.\n",
        "\n",
        "##Example: 10-5 =5\n"
      ],
      "metadata": {
        "id": "-5afpbCgMvyd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "num1 = 5\n",
        "num2 = 3\n",
        "product = num1 * num2\n",
        "\n",
        "print(f\"The product of {num1} and {num2} is: {product}\")\n",
        "\n",
        "\n",
        "num3 = 10\n",
        "num4 = 7\n",
        "sum_result = num3 + num4\n",
        "\n",
        "print(f\"The sum of {num3} and {num4} is: {sum_result}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cwz6ao2uNGND",
        "outputId": "c60fd1f2-9682-4229-9d33-b479f27d123b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The product of 5 and 3 is: 15\n",
            "The sum of 10 and 7 is: 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert minutes to hours and minutes\n",
        "total_minutes = 150\n",
        "\n",
        "hours = total_minutes // 60\n",
        "remaining_minutes = total_minutes % 60\n",
        "\n",
        "print(f\"{total_minutes} minutes is equal to {hours} hours and {remaining_minutes} minutes.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgIqaCGRNS9v",
        "outputId": "f9955509-9faf-49f4-e647-1dee5141db6a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150 minutes is equal to 2 hours and 30 minutes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Objectives\n",
        "\n",
        "# In this notebook, we aim to achieve the following objectives:\n",
        "\n",
        "# 1. **Explore Data**: Load and explore the dataset to gain insights into its structure, features, and distribution.\n",
        "\n",
        "# 2. **Preprocess Data**: Clean and preprocess the data by handling missing values, outliers, and performing any necessary transformations.\n",
        "\n",
        "# 3. **Visualize Data**: Create informative visualizations to better understand patterns, relationships, and trends within the dataset.\n",
        "\n",
        "# 4. **Feature Engineering**: Engineer new features or select relevant features to improve model performance.\n",
        "\n",
        "# 5. **Build Model**: Choose an appropriate machine learning algorithm, train the model using the dataset, and fine-tune its parameters.\n",
        "\n",
        "# 6. **Evaluate Model**: Assess the model's performance using appropriate evaluation metrics and techniques.\n",
        "\n",
        "# 7. **Interpret Results**: Interpret the model's outcomes, gain insights from its predictions, and draw meaningful conclusions.\n",
        "\n",
        "# 8. **Communicate Findings**: Summarize the analysis, insights, and outcomes in a clear and concise manner.\n",
        "\n",
        "# Throughout the notebook, we'll work step by step to accomplish these objectives and gain a comprehensive understanding of the data and its implications.\n"
      ],
      "metadata": {
        "id": "lXOj_hpSNgfQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Author\n",
        "\n",
        "# This notebook was created by: Ritik Raj\n"
      ],
      "metadata": {
        "id": "VUb5ohHYN2Vq"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}